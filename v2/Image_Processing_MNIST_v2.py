## IMAGE PROCESSING USING MNIST DATABSE ##
# Created by: Hermes Ponce
#===================================================================
# APPROACH:
# For this competition, we will be using Keras (with TensorFlow as our backend) as 
# the main package to create a simple neural network to predict, as accurately as we can, 
# digits from handwritten images. In particular, we will be calling the Functional Model API 
# of Keras, and creating a 4-layered and 5-layered neural network.

# Also, we will be experimenting with various optimizers: the plain vanilla Stochastic Gradient 
# Descent optimizer and the Adam optimizer. However, there are many other parameters, such as 
# training epochs which will we will not be experimenting with.

# In addition, the choice of hidden layer units are completely arbitrary and may not be optimal.
# This is yet another parameter which we will not attempt to tinker with. Lastly, we introduce 
# dropout, a form of regularisation, in our neural networks to prevent overfitting.

# RESULT:
# Following our simulations on the cross validation dataset, it appears that a 4-layered neural 
# network, using 'Adam' as the optimizer along with a learning rate of 0.01, performs best. 
# We proceed to introduce dropout in the model, and use the model to predict for the test set.

# The test predictions (submitted to Kaggle) generated by our model predicts with an accuracy 
# score of 97.600%, which places us at the top 55 percentile of the competition.

#===================================================================
from IPython import get_ipython
get_ipython().magic('reset -sf')

# Importing key libraries and reading data
import pandas as pd
import numpy as np

np.random.seed(1212)

# In this case, we use keras instead of TensorFlow directly (it is backend)
import keras
from keras.models import Model
from keras.layers import *
from keras import optimizers

df_train = pd.read_csv('train.csv')
df_test = pd.read_csv('test.csv')
df_train.head()

# Splitting into training and validation dataset
df_features = df_train.iloc[:, 1:785]
df_label = df_train.iloc[:, 0]

X_test = df_test.iloc[:, 0:784]
print(X_test.shape)

from sklearn.model_selection import train_test_split
X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label, 
                                                test_size = 0.2,
                                                random_state = 1212)

X_train = X_train.values.reshape(33600, 784) #(33600, 784)
X_cv = X_cv.values.reshape(8400, 784) #(8400, 784)
X_test = X_test.values.reshape(28000, 784)

# Data cleaning, normalization and selection
print((min(X_train[1]), max(X_train[1])))
# As the pixel intensities are currently between the range of 0 and 255, 
# we proceed to normalize the features, using broadcasting. 
# In addition, we proceed to convert our labels from a class vector to binary One Hot Encoded

# Feature Normalization 
X_train = X_train.astype('float32'); X_cv= X_cv.astype('float32'); X_test = X_test.astype('float32')
X_train /= 255; X_cv /= 255; X_test /= 255

# Convert labels to One Hot Encoded
num_digits = 10
y_train = keras.utils.to_categorical(y_train, num_digits)
y_cv = keras.utils.to_categorical(y_cv, num_digits)

# Printing 2 examples of labels after conversion
print(y_train[0]) # 2
print(y_train[3]) # 7

# Model fitting
# Input Parameters
n_input = 784 # number of features
n_hidden_1 = 300
n_hidden_2 = 100
n_hidden_3 = 100
n_hidden_4 = 200
num_digits = 10

# we will use the Keras library to train a neural network with the activation function set as ReLu.
# To determine which class to output, we will rely on the SoftMax function
Inp = Input(shape=(784,))
x = Dense(n_hidden_1, activation='relu', name = "Hidden_Layer_1")(Inp)
x = Dense(n_hidden_2, activation='relu', name = "Hidden_Layer_2")(x)
x = Dense(n_hidden_3, activation='relu', name = "Hidden_Layer_3")(x)
x = Dense(n_hidden_4, activation='relu', name = "Hidden_Layer_4")(x)
output = Dense(num_digits, activation='softmax', name = "Output_Layer")(x)

# Our model would have '6' layers: input layer, 4 hidden layer and 1 output layer
model1 = Model(Inp, output)
model1.summary() # We have 297,910 parameters to estimate

# Insert Hyperparameters
learning_rate = 0.1
training_epochs = 20
batch_size = 100
sgd = optimizers.SGD(learning_rate=learning_rate)

# Using a 4 layer neural network with:
# 20 training epochs
# A training batch size of 100
# Hidden layers set as (300, 100, 100, 200)
# Learning rate of 0.1

# We rely on the plain vanilla Stochastic Gradient Descent as our optimizing methodology
model1.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])

history1 = model1.fit(X_train, y_train,
                     batch_size = batch_size,
                     epochs = training_epochs,
                     verbose = 2,
                     validation_data=(X_cv, y_cv))

# We rely on ADAM as our optimizing methodology
adam = keras.optimizers.Adam(learning_rate=learning_rate)
model2 = Model(Inp, output)

model2.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history2 = model2.fit(X_train, y_train,
                      batch_size = batch_size,
                      epochs = training_epochs,
                      verbose = 2,
                      validation_data=(X_cv, y_cv))

# Going forward, we will use 'Adam' as our optimizer of choice.

# What if we changed the learning rate from 0.1 to 0.01, or 0.5? 
# Will it have any impact on the accuracy? Model 2A
learning_rate = 0.01
adam = keras.optimizers.Adam(learning_rate=learning_rate)
model2A = Model(Inp, output)

model2A.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history2A = model2A.fit(X_train, y_train,
                      batch_size = batch_size,
                      epochs = training_epochs,
                      verbose = 2,
                      validation_data=(X_cv, y_cv))

# Now we add a new layer
# Input Parameters
n_input = 784 # number of features
n_hidden_1 = 300
n_hidden_2 = 100
n_hidden_3 = 100
n_hidden_4 = 100
n_hidden_5 = 200
num_digits = 10

Inp = Input(shape=(784,))
x = Dense(n_hidden_1, activation='relu', name = "Hidden_Layer_1")(Inp)
x = Dense(n_hidden_2, activation='relu', name = "Hidden_Layer_2")(x)
x = Dense(n_hidden_3, activation='relu', name = "Hidden_Layer_3")(x)
x = Dense(n_hidden_4, activation='relu', name = "Hidden_Layer_4")(x)
x = Dense(n_hidden_5, activation='relu', name = "Hidden_Layer_5")(x)
output = Dense(num_digits, activation='softmax', name = "Output_Layer")(x)

# Our model would have '7' layers - input layer, 5 hidden layer and 1 output layer
model3 = Model(Inp, output)
model3.summary() # We have 308,010 parameters to estimate

# We rely on 'Adam' as our optimizing methodology
adam = keras.optimizers.Adam(learning_rate=0.01)

model3.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history3 = model3.fit(X_train, y_train,
                      batch_size = batch_size,
                      epochs = training_epochs,
                      validation_data=(X_cv, y_cv))

# Compared to our first model, adding an additional layer did not significantly improve the accuracy from our previous model.
# We now proceed to include dropout (dropout rate of 0.3) in our second model to prevent overfitting.

test_pred = pd.DataFrame(model3.predict(X_test, batch_size=200))
test_pred = pd.DataFrame(test_pred.idxmax(axis = 1))
test_pred.index.name = 'ImageId'
test_pred = test_pred.rename(columns = {0: 'Label'}).reset_index()
test_pred['ImageId'] = test_pred['ImageId'] + 1
test_pred.head()

# Check the prediction values
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib.cm as cm
# Each row represents an image of a handwritten digit and a label with the value of this digit
# Every image is a stretched array of 785 pixels values (28x28 px)
images = df_test.iloc[:,0:].values
images = images.astype(np.float64) # Convert into floating points

# Convert from [0:255] => [0.0:1.0]
images = np.multiply(images, 1.0 / 255.0)
image_size = images.shape[1]
# In this case all images are square
image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)
print ('image_width => {0}\nimage_height => {1}'.format(image_width,image_height))

# To output one of the images, we reshape this long string of pixels into a 2-dimensional array, which is basically a grayscale image.
def display(img):
    # (784) => (28,28)
    one_image = img.reshape(image_width,image_height)
    
    plt.axis('off')
    plt.imshow(one_image, cmap=cm.binary)

# If you want to change the colormaps (cmap='viridis')
from matplotlib import colormaps
list(colormaps)

# Single output image  
Disp_Img = 50 
display(images[Disp_Img])
print ('Image Predicted => {0}'.format(test_pred.iloc[Disp_Img,1]))

# PREVIEW PREDICTIONS
plt.figure(figsize=(15,6))
for i in range(50):  
    plt.subplot(5, 10, i+1)
    one_image = images[i].reshape(image_width,image_height)
    plt.imshow(one_image,cmap=cm.binary)
    plt.title("predict=%d" % test_pred.iloc[i,1],y=0.9)
    plt.axis('off')
plt.subplots_adjust(wspace=0.3, hspace=-0.1)
plt.show()

# Save the file in the Kaggle format to submission
test_pred.to_csv('mnist_submission.csv', index = False)





























